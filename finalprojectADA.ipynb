{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4119 entries, 0 to 4118\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             4119 non-null   int64  \n",
      " 1   job             4119 non-null   object \n",
      " 2   marital         4119 non-null   object \n",
      " 3   education       4119 non-null   object \n",
      " 4   default         4119 non-null   object \n",
      " 5   housing         4119 non-null   object \n",
      " 6   loan            4119 non-null   object \n",
      " 7   contact         4119 non-null   object \n",
      " 8   month           4119 non-null   object \n",
      " 9   day_of_week     4119 non-null   object \n",
      " 10  duration        4119 non-null   int64  \n",
      " 11  campaign        4119 non-null   int64  \n",
      " 12  pdays           4119 non-null   int64  \n",
      " 13  previous        4119 non-null   int64  \n",
      " 14  poutcome        4119 non-null   object \n",
      " 15  emp.var.rate    4119 non-null   float64\n",
      " 16  cons.price.idx  4119 non-null   float64\n",
      " 17  cons.conf.idx   4119 non-null   float64\n",
      " 18  euribor3m       4119 non-null   float64\n",
      " 19  nr.employed     4119 non-null   float64\n",
      " 20  y               4119 non-null   object \n",
      "dtypes: float64(5), int64(5), object(11)\n",
      "memory usage: 675.9+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "X = pd.read_csv(\"bank-additional.csv\", delimiter=';')\n",
    "X.head()\n",
    "X.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# UCIMLRepo says to remove this, since the outcome of this data is not known before the call, so its useless for prediction\n",
    "X = X.drop('duration', axis=1)\n",
    "#Feature Engineering to remove the 999 values in pdays, and create a new binary class instead( \"contacted\")\n",
    "X['contacted'] = X['pdays'].apply(lambda x: 0 if x == 999 else 1)\n",
    "X=X.drop('pdays',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'campaign', 'previous', 'emp.var.rate', 'cons.price.idx',\n",
      "       'cons.conf.idx', 'euribor3m', 'nr.employed', 'contacted'],\n",
      "      dtype='object')\n",
      "Index(['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact',\n",
      "       'month', 'day_of_week', 'poutcome'],\n",
      "      dtype='object')\n",
      "List of Numeric Columns: Index(['age', 'campaign', 'previous', 'emp.var.rate', 'cons.price.idx',\n",
      "       'cons.conf.idx', 'euribor3m', 'nr.employed', 'contacted'],\n",
      "      dtype='object')\n",
      "List of Categorical Columns: Index(['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact',\n",
      "       'month', 'day_of_week', 'poutcome'],\n",
      "      dtype='object')\n",
      "\n",
      "Data Preprocessor Pipeline:\n",
      "ColumnTransformer(transformers=[('numeric',\n",
      "                                 Pipeline(steps=[('median_imputer',\n",
      "                                                  SimpleImputer(strategy='median')),\n",
      "                                                 ('standard_scaler',\n",
      "                                                  StandardScaler())]),\n",
      "                                 Index(['age', 'campaign', 'previous', 'emp.var.rate', 'cons.price.idx',\n",
      "       'cons.conf.idx', 'euribor3m', 'nr.employed', 'contacted'],\n",
      "      dtype='object')),\n",
      "                                ('categorical',\n",
      "                                 Pipeline(steps=[('fill_missing',\n",
      "                                                  SimpleImputer(fill_value='missing',\n",
      "                                                                strategy='constant')),\n",
      "                                                 ('one_hot_encoder',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'))]),\n",
      "                                 Index(['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact',\n",
      "       'month', 'day_of_week', 'poutcome'],\n",
      "      dtype='object'))])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Segregating the target variable 'y' and features\n",
    "target_var = X[['y']]\n",
    "features = X.drop(columns=['y'])\n",
    "\n",
    "# Partitioning data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target_var, test_size=0.1, random_state=42)\n",
    "\n",
    "# Distinguishing between numeric and categorical columns\n",
    "numeric_cols = features.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols = features.select_dtypes(include=['object']).columns\n",
    "print(numeric_cols)\n",
    "print(categorical_cols)\n",
    "\n",
    "print(\"List of Numeric Columns:\", numeric_cols)\n",
    "print(\"List of Categorical Columns:\", categorical_cols)\n",
    "\n",
    "# Setting up preprocessing for numeric data\n",
    "numeric_prep = Pipeline([\n",
    "    ('median_imputer', SimpleImputer(strategy='median')),\n",
    "    ('standard_scaler', StandardScaler())])\n",
    "\n",
    "# Setting up preprocessing for categorical data\n",
    "categorical_prep = Pipeline([\n",
    "    ('fill_missing', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Combining preprocessing steps\n",
    "data_preprocessor = ColumnTransformer([\n",
    "    ('numeric', numeric_prep, numeric_cols),\n",
    "    ('categorical', categorical_prep, categorical_cols)])\n",
    "print(\"\\nData Preprocessor Pipeline:\")\n",
    "print(data_preprocessor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Selection and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eren\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.91      0.99      0.95       370\n",
      "         yes       0.62      0.19      0.29        42\n",
      "\n",
      "    accuracy                           0.91       412\n",
      "   macro avg       0.77      0.59      0.62       412\n",
      "weighted avg       0.88      0.91      0.88       412\n",
      "\n",
      "ROC AUC Score for Logistic Regression: 0.7138996138996139\n",
      "Precision Score for Logistic Regression: 0.3713615242754769\n",
      "Classification Report for Gradient Boosting:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.92      0.99      0.95       370\n",
      "         yes       0.64      0.21      0.32        42\n",
      "\n",
      "    accuracy                           0.91       412\n",
      "   macro avg       0.78      0.60      0.64       412\n",
      "weighted avg       0.89      0.91      0.89       412\n",
      "\n",
      "ROC AUC Score for Gradient Boosting: 0.7212033462033463\n",
      "Precision Score for Gradient Boosting: 0.3799621620537865\n",
      "Classification Report for AdaBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.92      0.99      0.95       370\n",
      "         yes       0.69      0.26      0.38        42\n",
      "\n",
      "    accuracy                           0.91       412\n",
      "   macro avg       0.80      0.62      0.67       412\n",
      "weighted avg       0.90      0.91      0.89       412\n",
      "\n",
      "ROC AUC Score for AdaBoost: 0.7347490347490347\n",
      "Precision Score for AdaBoost: 0.4101187427808306\n",
      "Classification Report for SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.91      0.99      0.95       370\n",
      "         yes       0.62      0.12      0.20        42\n",
      "\n",
      "    accuracy                           0.90       412\n",
      "   macro avg       0.77      0.56      0.57       412\n",
      "weighted avg       0.88      0.90      0.87       412\n",
      "\n",
      "ROC AUC Score for SVM: 0.6933075933075933\n",
      "Precision Score for SVM: 0.3458554376484039\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Defining a list of classifier names and corresponding classifier objects\n",
    "classifier_names = [\"Logistic Regression\", \"Gradient Boosting\", \"AdaBoost\", \"SVM\"]\n",
    "classifiers_list = [\n",
    "    LogisticRegression(random_state=42),\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    AdaBoostClassifier(random_state=42),\n",
    "    SVC(probability=True, random_state=42)\n",
    "]\n",
    "\n",
    "# Iterating over each classifier for training and evaluation\n",
    "for name, clf in zip(classifier_names, classifiers_list):\n",
    "    # Building a pipeline with preprocessing and classification\n",
    "    pipeline = Pipeline([('data_prep', data_preprocessor),\n",
    "                         ('clf', clf)])\n",
    "    # Fitting the model on training data\n",
    "    pipeline.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    # Making predictions and evaluating the model\n",
    "    predicted_probs = pipeline.predict_proba(X_test)[:, 1]\n",
    "    predictions = pipeline.predict(X_test)\n",
    "\n",
    "    # Converting string labels to binary for ROC AUC and Precision Score computation\n",
    "    label_binarizer = LabelBinarizer()\n",
    "    binary_test_labels = label_binarizer.fit_transform(y_test)\n",
    "\n",
    "    # Displaying the classification report\n",
    "    print(f\"Classification Report for {name}:\")\n",
    "    print(classification_report(y_test, predictions))\n",
    "\n",
    "    # Calculating and displaying ROC AUC and Precision Scores\n",
    "    roc_score = roc_auc_score(binary_test_labels, predicted_probs)\n",
    "    print(f\"ROC AUC Score for {name}: {roc_score}\")\n",
    "    precision_score = average_precision_score(binary_test_labels, predicted_probs)\n",
    "    print(f\"Precision Score for {name}: {precision_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning (for AdaBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eren\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'ada_classifier__n_estimators': 50, 'ada_classifier__learning_rate': 0.1}\n",
      "Confusion Matrix:\n",
      " [[367   3]\n",
      " [ 36   6]]\n",
      "Accuracy Score: 0.9053398058252428\n",
      "ROC AUC Score for Best Model: 0.739060489060489\n",
      "Average Precision Score for Best Model: 0.413016186326996\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Defining the model pipeline\n",
    "model_pipeline = Pipeline([\n",
    "    ('data_preprocessing', preprocessor),\n",
    "    ('ada_classifier', AdaBoostClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Parameter grid for RandomizedSearchCV\n",
    "param_distributions = {\n",
    "    'ada_classifier__n_estimators': np.arange(50, 301, 50),\n",
    "    'ada_classifier__learning_rate': np.logspace(-2, 0, 5)\n",
    "}\n",
    "\n",
    "# Using RandomizedSearchCV for hyperparameter tuning\n",
    "random_search = RandomizedSearchCV(model_pipeline, param_distributions, n_iter=10, cv=5, scoring='roc_auc', n_jobs=-1, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Extracting the best parameters and the best model\n",
    "best_parameters = random_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_parameters)\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Making predictions with the best model\n",
    "y_predictions = best_model.predict(X_test)\n",
    "y_predicted_probs = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Binarizing the y_test for ROC AUC and Average Precision calculations\n",
    "label_binarizer = LabelBinarizer()\n",
    "binary_test_labels = label_binarizer.fit_transform(y_test)\n",
    "\n",
    "# Generating a confusion matrix and accuracy score\n",
    "conf_matrix = confusion_matrix(y_test, y_predictions)\n",
    "accuracy = accuracy_score(y_test, y_predictions)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Accuracy Score:\", accuracy)\n",
    "\n",
    "# Calculating and displaying ROC AUC and Average Precision Scores\n",
    "roc_auc_score = roc_auc_score(binary_test_labels, y_predicted_probs)\n",
    "average_precision_score = average_precision_score(binary_test_labels, y_predicted_probs)\n",
    "print(f\"ROC AUC Score for Best Model: {roc_auc_score}\")\n",
    "print(f\"Average Precision Score for Best Model: {average_precision_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
